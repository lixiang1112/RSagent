#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MMchange.py ç›´æ¥è¿è¡ŒéªŒè¯è„šæœ¬

è¯¥è„šæœ¬éªŒè¯ MMchange.py æ˜¯å¦èƒ½å¤Ÿï¼š
1. æˆåŠŸå¯¼å…¥æ‰€æœ‰ä¾èµ–
2. æ­£ç¡®åˆå§‹åŒ–æ¨¡å‹
3. æ‰§è¡Œå˜åŒ–æ£€æµ‹æ¨ç†
4. ç”Ÿæˆå¯è§†åŒ–ç»“æœ

ä½¿ç”¨æ–¹æ³•ï¼š
python test_mmchange_direct.py [--device cuda:0]
"""

import sys
import os
import torch
import traceback
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = "/root/Remote-Sensing-ChatGPT"
sys.path.insert(0, PROJECT_ROOT)

def print_section(title):
    """æ‰“å°åˆ†éš”çº¿æ ‡é¢˜"""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨"""
    print_section("æ­¥éª¤ 1: æ£€æŸ¥ä¾èµ–")
    
    dependencies = {
        'torch': 'PyTorch',
        'PIL': 'Pillow',
        'clip': 'CLIP',
        'cv2': 'OpenCV',
        'numpy': 'NumPy',
    }
    
    all_good = True
    for module_name, display_name in dependencies.items():
        try:
            __import__(module_name)
            print(f"  âœ“ {display_name} ({module_name})")
        except ImportError as e:
            print(f"  âœ— {display_name} ({module_name}) - æœªå®‰è£…æˆ–æ— æ³•å¯¼å…¥")
            print(f"    é”™è¯¯: {e}")
            all_good = False
    
    return all_good

def check_model_file():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print_section("æ­¥éª¤ 2: æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")
    
    model_path = '/root/MMchange-main/results_change_caption_transfer_LEVIR_iter_40000_lr_0.0005/best_model.pth'
    
    if os.path.exists(model_path):
        file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB
        print(f"  âœ“ æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {model_path}")
        print(f"  âœ“ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
        return True
    else:
        print(f"  âœ— æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return False

def check_mmchange_modules():
    """æ£€æŸ¥ MMchange ç›¸å…³æ¨¡å—æ˜¯å¦å¯å¯¼å…¥"""
    print_section("æ­¥éª¤ 3: æ£€æŸ¥ MMchange æ¨¡å—")
    
    all_good = True
    
    # æ£€æŸ¥ Transforms
    try:
        MMCHANGE_PATH = '/root/MMchange-main'
        sys.path.insert(0, MMCHANGE_PATH)
        import Transforms as myTransforms
        print(f"  âœ“ Transforms æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"  âœ— Transforms æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        all_good = False
    
    # æ£€æŸ¥ model æ¨¡å—
    try:
        from models.model import BaseNet, BaseNet_Hybrid
        print(f"  âœ“ models.model æ¨¡å—å¯¼å…¥æˆåŠŸ")
    except Exception as e:
        print(f"  âœ— models.model æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        all_good = False
    
    return all_good

def test_mmchange_import():
    """æµ‹è¯• MMchange ç±»æ˜¯å¦å¯ä»¥å¯¼å…¥"""
    print_section("æ­¥éª¤ 4: æµ‹è¯• MMChangeDetection ç±»å¯¼å…¥")
    
    try:
        from RStask.ChangeDetection.MMchange import MMChangeDetection
        print(f"  âœ“ MMChangeDetection ç±»å¯¼å…¥æˆåŠŸ")
        return True, MMChangeDetection
    except Exception as e:
        print(f"  âœ— MMChangeDetection ç±»å¯¼å…¥å¤±è´¥:")
        print(f"    {e}")
        traceback.print_exc()
        return False, None

def test_mmchange_initialization(MMChangeDetection, device='cuda:0'):
    """æµ‹è¯• MMchange æ¨¡å‹åˆå§‹åŒ–"""
    print_section(f"æ­¥éª¤ 5: æµ‹è¯•æ¨¡å‹åˆå§‹åŒ– (è®¾å¤‡: {device})")
    
    # å¦‚æœæ˜¯ cuda è®¾å¤‡ï¼Œæ£€æŸ¥æ˜¯å¦å¯ç”¨
    if 'cuda' in device:
        if not torch.cuda.is_available():
            print(f"  âš  CUDA ä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ° CPU")
            device = 'cpu'
        else:
            print(f"  âœ“ CUDA å¯ç”¨")
            print(f"    GPU è®¾å¤‡: {torch.cuda.get_device_name(0)}")
    
    try:
        detector = MMChangeDetection(device=device)
        print(f"  âœ“ æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        return True, detector
    except Exception as e:
        print(f"  âœ— æ¨¡å‹åˆå§‹åŒ–å¤±è´¥:")
        print(f"    {e}")
        traceback.print_exc()
        return False, None

def create_test_images():
    """åˆ›å»ºæµ‹è¯•å›¾åƒï¼ˆå¦‚æœæ²¡æœ‰ç°æˆçš„ï¼‰"""
    print_section("æ­¥éª¤ 6: å‡†å¤‡æµ‹è¯•å›¾åƒ")
    
    from PIL import Image
    import numpy as np
    
    test_dir = "/root/Remote-Sensing-ChatGPT/test_images"
    os.makedirs(test_dir, exist_ok=True)
    
    pre_image_path = os.path.join(test_dir, "test_pre.png")
    post_image_path = os.path.join(test_dir, "test_post.png")
    
    # å¦‚æœæµ‹è¯•å›¾åƒå·²å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨
    if os.path.exists(pre_image_path) and os.path.exists(post_image_path):
        print(f"  âœ“ ä½¿ç”¨ç°æœ‰æµ‹è¯•å›¾åƒ")
        print(f"    å‰æ—¶ç›¸: {pre_image_path}")
        print(f"    åæ—¶ç›¸: {post_image_path}")
        return pre_image_path, post_image_path
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•å›¾åƒï¼ˆ256x256 RGBï¼‰
    print(f"  âš  æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒï¼Œåˆ›å»ºæ¨¡æ‹Ÿå›¾åƒ...")
    
    # å‰æ—¶ç›¸ï¼šç»¿è‰²èƒŒæ™¯ï¼ˆæ¨¡æ‹Ÿæ¤è¢«ï¼‰
    pre_img = np.ones((256, 256, 3), dtype=np.uint8) * [50, 150, 50]
    # æ·»åŠ ä¸€äº›çº¹ç†
    np.random.seed(42)
    noise = np.random.randint(-20, 20, (256, 256, 3))
    pre_img = np.clip(pre_img + noise, 0, 255).astype(np.uint8)
    
    # åæ—¶ç›¸ï¼šåœ¨æŸäº›åŒºåŸŸæ·»åŠ å»ºç­‘ç‰©ï¼ˆç°è‰²ï¼‰
    post_img = pre_img.copy()
    # æ·»åŠ ä¸€äº›"å»ºç­‘ç‰©"ï¼ˆç°è‰²çŸ©å½¢ï¼‰
    post_img[50:100, 50:150] = [150, 150, 150]
    post_img[120:200, 180:230] = [140, 140, 140]
    
    # ä¿å­˜å›¾åƒ
    Image.fromarray(pre_img).save(pre_image_path)
    Image.fromarray(post_img).save(post_image_path)
    
    print(f"  âœ“ æµ‹è¯•å›¾åƒåˆ›å»ºæˆåŠŸ")
    print(f"    å‰æ—¶ç›¸: {pre_image_path}")
    print(f"    åæ—¶ç›¸: {post_image_path}")
    
    return pre_image_path, post_image_path

def test_inference(detector, pre_image_path, post_image_path):
    """æµ‹è¯•å˜åŒ–æ£€æµ‹æ¨ç†"""
    print_section("æ­¥éª¤ 7: æµ‹è¯•å˜åŒ–æ£€æµ‹æ¨ç†")
    
    output_dir = "/root/Remote-Sensing-ChatGPT/test_results"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "test_result.png")
    
    print(f"  è¾“å…¥:")
    print(f"    å‰æ—¶ç›¸: {pre_image_path}")
    print(f"    åæ—¶ç›¸: {post_image_path}")
    print(f"  è¾“å‡º:")
    print(f"    ç»“æœå›¾åƒ: {output_path}")
    print()
    
    try:
        result_text = detector.inference(
            pre_image_path=pre_image_path,
            post_image_path=post_image_path,
            output_path=output_path,
            change_caption="buildings have been constructed or demolished"
        )
        
        print(f"\n  âœ“ æ¨ç†æ‰§è¡ŒæˆåŠŸ")
        print(f"    {result_text}")
        
        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
        if os.path.exists(output_path):
            file_size = os.path.getsize(output_path) / 1024  # KB
            print(f"  âœ“ ç»“æœæ–‡ä»¶å·²ç”Ÿæˆ")
            print(f"    è·¯å¾„: {output_path}")
            print(f"    å¤§å°: {file_size:.2f} KB")
            return True
        else:
            print(f"  âœ— ç»“æœæ–‡ä»¶æœªç”Ÿæˆ")
            return False
            
    except Exception as e:
        print(f"  âœ— æ¨ç†æ‰§è¡Œå¤±è´¥:")
        print(f"    {e}")
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='MMchange.py ç›´æ¥è¿è¡ŒéªŒè¯')
    parser.add_argument('--device', type=str, default='cuda:0',
                       choices=['cuda:0', 'cuda:1', 'cpu'],
                       help='è®¾å¤‡ç±»å‹')
    parser.add_argument('--pre_image', type=str, default=None,
                       help='å‰æ—¶ç›¸å›¾åƒè·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨æµ‹è¯•å›¾åƒï¼‰')
    parser.add_argument('--post_image', type=str, default=None,
                       help='åæ—¶ç›¸å›¾åƒè·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨æµ‹è¯•å›¾åƒï¼‰')
    
    args = parser.parse_args()
    
    print("\n")
    print("â•”" + "â•" * 68 + "â•—")
    print("â•‘" + " " * 15 + "MMchange.py ç›´æ¥è¿è¡ŒéªŒè¯" + " " * 29 + "â•‘")
    print("â•š" + "â•" * 68 + "â•")
    
    # è®°å½•æµ‹è¯•ç»“æœ
    test_results = {}
    
    # 1. æ£€æŸ¥ä¾èµ–
    test_results['dependencies'] = check_dependencies()
    if not test_results['dependencies']:
        print("\nâŒ ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·å…ˆå®‰è£…ç¼ºå¤±çš„ä¾èµ–")
        return False
    
    # 2. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    test_results['model_file'] = check_model_file()
    if not test_results['model_file']:
        print("\nâŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå‡†å¤‡æ¨¡å‹æ–‡ä»¶")
        return False
    
    # 3. æ£€æŸ¥ MMchange æ¨¡å—
    test_results['mmchange_modules'] = check_mmchange_modules()
    if not test_results['mmchange_modules']:
        print("\nâŒ MMchange æ¨¡å—å¯¼å…¥å¤±è´¥")
        return False
    
    # 4. æµ‹è¯• MMChangeDetection å¯¼å…¥
    success, MMChangeDetection = test_mmchange_import()
    test_results['mmchange_import'] = success
    if not success:
        print("\nâŒ MMChangeDetection ç±»å¯¼å…¥å¤±è´¥")
        return False
    
    # 5. æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–
    success, detector = test_mmchange_initialization(MMChangeDetection, args.device)
    test_results['initialization'] = success
    if not success:
        print("\nâŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
        return False
    
    # 6. å‡†å¤‡æµ‹è¯•å›¾åƒ
    if args.pre_image and args.post_image:
        pre_image_path = args.pre_image
        post_image_path = args.post_image
        print_section("æ­¥éª¤ 6: ä½¿ç”¨æŒ‡å®šçš„æµ‹è¯•å›¾åƒ")
        print(f"  å‰æ—¶ç›¸: {pre_image_path}")
        print(f"  åæ—¶ç›¸: {post_image_path}")
    else:
        pre_image_path, post_image_path = create_test_images()
    
    # 7. æµ‹è¯•æ¨ç†
    test_results['inference'] = test_inference(detector, pre_image_path, post_image_path)
    
    # æ€»ç»“
    print_section("éªŒè¯ç»“æœæ€»ç»“")
    
    all_passed = True
    for test_name, result in test_results.items():
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"  {test_name:20s}: {status}")
        if not result:
            all_passed = False
    
    print("\n" + "=" * 70)
    if all_passed:
        print("  ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼MMchange.py å¯ä»¥ç›´æ¥è¿è¡Œ")
    else:
        print("  âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    print("=" * 70 + "\n")
    
    return all_passed

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)

