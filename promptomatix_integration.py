"""
Promptomatix è½»é‡çº§é›†æˆ - ä»…ç”¨äºåŠ¨æ€æŸ¥è¯¢ä¼˜åŒ–
ç®€åŒ–ç‰ˆï¼šä¸ä¾èµ– dspyï¼Œç›´æ¥ä½¿ç”¨ OpenAI API
"""
import sys
import os
from typing import Optional
import logging

class QueryOptimizer:
    """è½»é‡çº§æŸ¥è¯¢ä¼˜åŒ–å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰- é’ˆå¯¹é¥æ„Ÿå›¾åƒå¤„ç†ä¼˜åŒ–"""
    
    def __init__(self, model_name="gpt-3.5-turbo", openai_key=None, proxy_url=None, enabled=True):
        self.enabled = enabled
        self.model_name = model_name
        self.openai_key = openai_key or os.getenv('OPENAI_API_KEY')
        self.proxy_url = proxy_url or "https://api.openai.com/v1"
        self.cache = {}  # æŸ¥è¯¢ç¼“å­˜
        self.cache_size = 100
        self.optimization_count = 0  # ç»Ÿè®¡ä¼˜åŒ–æ¬¡æ•°
        self.skip_count = 0  # ç»Ÿè®¡è·³è¿‡æ¬¡æ•°
        
        # é¥æ„Ÿé¢†åŸŸä¸“ä¸šæœ¯è¯­æ˜ å°„
        self.rs_terminology = {
            # è¾¹ç¼˜/è¾¹ç•Œç›¸å…³
            'è¾¹ç•Œ': 'edge',
            'è¾¹ç¼˜': 'edge',
            'è½®å»“': 'edge',
            
            # æ£€æµ‹æ–¹å‘ç›¸å…³
            'æ¨ªå‘': 'horizontal',
            'æ°´å¹³': 'horizontal',
            'ç«–å‘': 'vertical',
            'å‚ç›´': 'vertical',
            'æ–œç€': 'rotated',
            'æ—‹è½¬': 'rotated',
            'å€¾æ–œ': 'rotated',
            
            # å›¾åƒè´¨é‡ç›¸å…³
            'æ¨¡ç³Š': 'blurry',
            'å™ªå£°': 'noisy',
            'å™ªç‚¹': 'noisy',
            'æ¸…æ™°': 'clear',
            
            # åœºæ™¯ç±»å‹
            'åŒºåŸŸ': 'area',
            'åœ°åŒº': 'area',
            'ç±»å‹': 'type',
            'åœºæ™¯': 'scene',
            
            # ç›®æ ‡ç›¸å…³
            'å»ºç­‘': 'building',
            'æˆ¿å±‹': 'building',
            'é“è·¯': 'road',
            'è½¦è¾†': 'vehicle',
            'é£æœº': 'plane',
            'èˆ¹': 'ship',
            
            # é¢œè‰²
            'ç»¿è‰²': 'green',
            'çº¢è‰²': 'red',
            'è“è‰²': 'blue',
            'ç™½è‰²': 'white',
            'é»‘è‰²': 'black',
        }
        
        # å·¥å…·å…³é”®è¯æ˜ å°„ï¼ˆç”¨äºä¿æŒè¯­ä¹‰ä¸€è‡´æ€§ï¼‰
        self.tool_keywords = {
            'EdgeDetection': ['è¾¹ç•Œ', 'è¾¹ç¼˜', 'è½®å»“', 'edge', 'boundary', 'contour'],
            'ChangeDetection': ['å˜åŒ–', 'ä¸åŒ', 'å¯¹æ¯”', 'å·®å¼‚', 'change', 'difference', 'compare'],
            'ObjectCounting': ['å¤šå°‘', 'æ•°é‡', 'è®¡æ•°', 'count', 'number', 'how many'],
            'ObjectDetection': ['æ‰¾å‡º', 'æ£€æµ‹', 'è¯†åˆ«', 'detect', 'find', 'identify'],
            'ImageCaptioning': ['æè¿°', 'ä»‹ç»', 'è¯´æ˜', 'describe', 'caption', 'explain'],
            'SceneClassification': ['ç±»å‹', 'åœºæ™¯', 'åˆ†ç±»', 'type', 'scene', 'classify', 'category'],
            'CloudRemoval': ['äº‘', 'å»äº‘', 'cloud', 'remove cloud'],
            'SuperResolution': ['æ¸…æ™°', 'åˆ†è¾¨ç‡', 'æ”¾å¤§', 'resolution', 'enhance', 'sharpen', 'clear'],
            'Denoising': ['å™ªå£°', 'å™ªç‚¹', 'å»å™ª', 'noise', 'denoise', 'clean'],
            'HorizontalDetection': ['æ¨ªå‘', 'æ°´å¹³', 'horizontal'],
            'RotatedDetection': ['æ–œç€', 'æ—‹è½¬', 'å€¾æ–œ', 'rotated', 'tilted', 'angled'],
        }
        
        if self.enabled:
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=self.openai_key, base_url=self.proxy_url)
                print("âœ“ æŸ¥è¯¢ä¼˜åŒ–å™¨å·²å¯ç”¨ï¼ˆé¥æ„Ÿé¢†åŸŸä¸“ä¸šç‰ˆï¼‰")
            except ImportError as e:
                print(f"âš ï¸ OpenAI å¯¼å…¥å¤±è´¥ï¼ŒæŸ¥è¯¢ä¼˜åŒ–å·²ç¦ç”¨: {e}")
                self.enabled = False
    
    def _detect_intended_tool(self, query: str) -> Optional[str]:
        """æ£€æµ‹æŸ¥è¯¢æ„å›¾å¯¹åº”çš„å·¥å…·"""
        query_lower = query.lower()
        
        # ä¼˜å…ˆçº§æ£€æµ‹ï¼šæŸäº›å·¥å…·éœ€è¦æ›´ç²¾ç¡®çš„åŒ¹é…
        # 1. è¾¹ç¼˜æ£€æµ‹ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼Œå› ä¸ºå®¹æ˜“è¢«è¯¯åˆ¤ä¸ºè¶…åˆ†è¾¨ç‡ï¼‰
        if any(kw in query_lower for kw in ['è¾¹ç•Œ', 'è¾¹ç¼˜', 'è½®å»“']):
            return 'EdgeDetection'
        
        # 2. æ—‹è½¬æ£€æµ‹ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
        if any(kw in query_lower for kw in ['æ–œç€', 'æ—‹è½¬', 'å€¾æ–œ', 'rotated', 'tilted', 'angled']):
            return 'RotatedDetection'
        
        # 3. æ¨ªå‘æ£€æµ‹
        if any(kw in query_lower for kw in ['æ¨ªå‘', 'æ°´å¹³', 'horizontal']):
            return 'HorizontalDetection'
        
        # 4. å»å™ª vs è¶…åˆ†è¾¨ç‡ï¼ˆéœ€è¦åŒºåˆ†"æ¨¡ç³Š"çš„ä¸åŒå«ä¹‰ï¼‰
        if 'æ¨¡ç³Š' in query_lower or 'blur' in query_lower:
            if any(kw in query_lower for kw in ['å¤„ç†', 'å»å™ª', 'denoise', 'noise']):
                return 'Denoising'
            elif any(kw in query_lower for kw in ['æ¸…æ™°', 'åˆ†è¾¨ç‡', 'clear', 'resolution', 'sharpen']):
                return 'SuperResolution'
        
        # 5. å…¶ä»–å·¥å…·æŒ‰å…³é”®è¯åŒ¹é…
        for tool, keywords in self.tool_keywords.items():
            if tool in ['EdgeDetection', 'RotatedDetection', 'HorizontalDetection', 'Denoising', 'SuperResolution']:
                continue  # å·²ç»å¤„ç†è¿‡
            for keyword in keywords:
                if keyword in query_lower:
                    return tool
        return None
    
    def _rule_based_optimize(self, query: str, intended_tool: Optional[str]) -> Optional[str]:
        """åŸºäºè§„åˆ™çš„ä¼˜åŒ–ï¼ˆå¿«é€Ÿè·¯å¾„ï¼Œé¿å…APIè°ƒç”¨ï¼‰"""
        if not intended_tool:
            return None
        
        # æå–å›¾ç‰‡è·¯å¾„ï¼ˆæ”¯æŒå•ä¸ªæˆ–å¤šä¸ªï¼Œç”¨é€—å·åˆ†éš”ï¼‰
        import re
        image_paths = re.findall(r'(/[^\s,]+\.(?:png|jpg|jpeg))', query)
        
        if len(image_paths) == 0:
            image_path_str = ""
        elif len(image_paths) == 1:
            image_path_str = f" at {image_paths[0]}"
        else:
            # å¤šä¸ªå›¾ç‰‡è·¯å¾„ï¼Œç”¨äº ChangeDetection
            image_path_str = f" {','.join(image_paths)}"
        
        # åŸºäºå·¥å…·ç±»å‹ç”Ÿæˆä¼˜åŒ–æŸ¥è¯¢
        # æ³¨æ„ï¼šä½¿ç”¨ä¸å·¥å…·åç§°å®Œå…¨åŒ¹é…çš„åŠ¨ä½œæè¿°ï¼Œé¿å…Agentè¯¯é€‰å·¥å…·
        templates = {
            'EdgeDetection': f"Use Edge Detection On Image{image_path_str}.",
            'ChangeDetection': f"Use Change Detection On Image Pair{image_path_str}." if len(image_paths) >= 2 else None,
            'ObjectCounting': None,  # éœ€è¦ä¿ç•™å…·ä½“ç›®æ ‡ï¼Œä½¿ç”¨LLMä¼˜åŒ–
            'ObjectDetection': None,  # éœ€è¦ä¿ç•™å…·ä½“ç›®æ ‡ï¼Œä½¿ç”¨LLMä¼˜åŒ–
            'ImageCaptioning': f"Get Photo Description of the image{image_path_str}.",
            'SceneClassification': f"Use Scene Classification for Remote Sensing Image{image_path_str}.",
            'CloudRemoval': f"Use Cloud Removal On Image{image_path_str}.",
            'SuperResolution': f"Use Super Resolution On Image{image_path_str}.",
            'Denoising': f"Use Denoising On Image{image_path_str}.",
            'HorizontalDetection': f"Use Horizontal Detection On Image{image_path_str}.",
            'RotatedDetection': f"Use Rotated Detection On Image{image_path_str}.",
        }
        
        return templates.get(intended_tool)
    
    def optimize_query(self, user_query: str, image_context: Optional[str] = None) -> str:
        """
        ä¼˜åŒ–ç”¨æˆ·æŸ¥è¯¢ï¼Œä½¿å…¶æ›´æ¸…æ™°å’Œå…·ä½“ï¼ˆé’ˆå¯¹é¥æ„Ÿé¢†åŸŸä¼˜åŒ–ï¼‰
        
        Args:
            user_query: ç”¨æˆ·åŸå§‹æŸ¥è¯¢
            image_context: å¯é€‰çš„å›¾åƒä¸Šä¸‹æ–‡æè¿°
            
        Returns:
            ä¼˜åŒ–åçš„æŸ¥è¯¢æ–‡æœ¬
        """
        if not self.enabled:
            return user_query
        
        # è·³è¿‡ç®€å•çš„é—®å€™è¯­å’Œç¡®è®¤è¯­å¥
        simple_phrases = ['hi', 'hello', 'thanks', 'thank you', 'ok', 'yes', 'no', 'received', 'å¥½çš„', 'è°¢è°¢', 'æ”¶åˆ°']
        if user_query.lower().strip() in simple_phrases or len(user_query.strip()) < 3:
            self.skip_count += 1
            return user_query
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"{user_query}_{image_context}"
        if cache_key in self.cache:
            print("âœ“ ä½¿ç”¨ç¼“å­˜çš„ä¼˜åŒ–ç»“æœ")
            return self.cache[cache_key]
        
        # æ£€æµ‹æ„å›¾å·¥å…·
        intended_tool = self._detect_intended_tool(user_query)
        
        # å°è¯•åŸºäºè§„åˆ™çš„å¿«é€Ÿä¼˜åŒ–
        rule_based_result = self._rule_based_optimize(user_query, intended_tool)
        if rule_based_result:
            self.optimization_count += 1
            print(f"ğŸ”§ æŸ¥è¯¢ä¼˜åŒ– (#{self.optimization_count}) [è§„åˆ™]:")
            print(f"   åŸå§‹: {user_query}")
            print(f"   ä¼˜åŒ–: {rule_based_result}")
            print(f"   æ„å›¾: {intended_tool}")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            if len(self.cache) >= self.cache_size:
                self.cache.pop(next(iter(self.cache)))
            self.cache[cache_key] = rule_based_result
            return rule_based_result
        
        try:
            # æ„å»ºé’ˆå¯¹é¥æ„Ÿé¢†åŸŸçš„ä¼˜åŒ–æç¤º
            system_prompt = """You are a query optimization expert for remote sensing AI systems. 
Your task is to clarify and optimize user queries while PRESERVING the original semantic intent and technical terminology.

CRITICAL RULES for Remote Sensing Domain:
1. Edge/Boundary Detection:
   - "è¾¹ç•Œ" or "è¾¹ç¼˜" â†’ use "edge detection" (NOT "enhance sharpness" or "super resolution")
   - Example: "è®©è¾¹ç•Œæ›´æ¸…æ™°" â†’ "Detect edges in the image"

2. Direction-specific Detection:
   - "æ¨ªå‘" â†’ "horizontal detection"
   - "æ–œç€" or "æ—‹è½¬" â†’ "rotated detection" (NOT "tilted" or general "detect")
   - Example: "æ–œç€çš„å»ºç­‘" â†’ "Detect rotated buildings"

3. Image Quality Enhancement:
   - "æ¨¡ç³Š" with "æ¸…æ™°" â†’ "super resolution" (enhance clarity/resolution)
   - "æ¨¡ç³Š" with "å¤„ç†" â†’ "denoising" (remove noise)
   - Keep the distinction clear!

4. Terminology Mapping:
   - è¾¹ç•Œ/è¾¹ç¼˜ â†’ edge (NOT boundary)
   - æ–œç€/æ—‹è½¬ â†’ rotated (NOT tilted)
   - æ¨ªå‘ â†’ horizontal
   - æè¿° â†’ describe/caption (NOT analyze)

5. Preserve Key Technical Terms:
   - Keep specific object types (buildings, roads, vehicles)
   - Keep color attributes (green, red, blue)
   - Keep spatial relationships (horizontal, vertical, rotated)

Guidelines:
- Keep the optimized query concise (one sentence)
- Translate Chinese to English while preserving technical meaning
- Use precise remote sensing terminology
- DO NOT change the intended tool/action"""

            # æ„å»ºç”¨æˆ·æç¤ºï¼ŒåŒ…å«æ„å›¾å·¥å…·ä¿¡æ¯
            user_prompt = f"""Optimize this remote sensing task request:

User query: {user_query}"""
            
            if intended_tool:
                user_prompt += f"\nDetected intent: {intended_tool}"
            
            if image_context:
                user_prompt += f"\nImage context: {image_context}"
            
            user_prompt += "\n\nOptimized query (preserve the technical intent):"
            
            # è°ƒç”¨ OpenAI API
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.1,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„ç»“æœ
                max_tokens=150
            )
            
            optimized = response.choices[0].message.content.strip()
            
            # éªŒè¯ä¼˜åŒ–ç»“æœæ˜¯å¦ä¿æŒäº†åŸå§‹æ„å›¾
            if intended_tool:
                optimized_tool = self._detect_intended_tool(optimized)
                if optimized_tool and optimized_tool != intended_tool:
                    print(f"âš ï¸ ä¼˜åŒ–æ”¹å˜äº†å·¥å…·æ„å›¾: {intended_tool} â†’ {optimized_tool}ï¼Œä½¿ç”¨åŸæŸ¥è¯¢")
                    self.skip_count += 1
                    return user_query
            
            # å¦‚æœä¼˜åŒ–ç»“æœå¤ªçŸ­ï¼Œä½¿ç”¨åŸæŸ¥è¯¢
            if len(optimized) < 3:
                print(f"âš ï¸ ä¼˜åŒ–ç»“æœå¤ªçŸ­ (é•¿åº¦={len(optimized)})")
                self.skip_count += 1
                return user_query
            
            # ä¿å­˜åˆ°ç¼“å­˜
            if len(self.cache) >= self.cache_size:
                self.cache.pop(next(iter(self.cache)))  # ç§»é™¤æœ€æ—§çš„
            self.cache[cache_key] = optimized
            
            self.optimization_count += 1
            print(f"ğŸ”§ æŸ¥è¯¢ä¼˜åŒ– (#{self.optimization_count}):")
            print(f"   åŸå§‹: {user_query}")
            print(f"   ä¼˜åŒ–: {optimized}")
            if intended_tool:
                print(f"   æ„å›¾: {intended_tool}")
            return optimized
            
        except Exception as e:
            print(f"âš ï¸ æŸ¥è¯¢ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸæŸ¥è¯¢: {e}")
            self.skip_count += 1
            return user_query
    
    def optimize_if_ambiguous(self, user_query: str, image_context: Optional[str] = None) -> str:
        """
        ä»…å½“æŸ¥è¯¢æ¨¡ç³Šæ—¶æ‰ä¼˜åŒ–ï¼ˆæ›´ä¿å®ˆçš„ç­–ç•¥ï¼‰
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢
            image_context: å›¾åƒä¸Šä¸‹æ–‡
            
        Returns:
            ä¼˜åŒ–åçš„æŸ¥è¯¢
        """
        if not self.enabled:
            return user_query
        
        # å¯¹æ‰€æœ‰éç®€å•é—®å€™è¯­çš„æŸ¥è¯¢éƒ½è¿›è¡Œä¼˜åŒ–
        # è¿™æ ·å¯ä»¥æœ€å¤§åŒ–çœ‹åˆ°ä¼˜åŒ–æ•ˆæœ
        return self.optimize_query(user_query, image_context)
    
    def get_stats(self):
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'optimization_count': self.optimization_count,
            'skip_count': self.skip_count,
            'cache_size': len(self.cache)
        }

