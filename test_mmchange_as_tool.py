#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MMchange.py ä½œä¸º Tool è°ƒç”¨éªŒè¯è„šæœ¬

è¯¥è„šæœ¬éªŒè¯ MMchange.py æ˜¯å¦èƒ½å¤Ÿä½œä¸º LangChain Tool è¢«è°ƒç”¨ï¼š
1. æ£€æŸ¥ ChangeDetectionFunction æ˜¯å¦æ­£ç¡®å°è£…
2. æµ‹è¯•åœ¨ RSChatGPT ä¸­çš„ ChangeDetection å·¥å…·
3. éªŒè¯ tool çš„è¾“å…¥è¾“å‡ºæ ¼å¼
4. æµ‹è¯•å¤šç§è°ƒç”¨åœºæ™¯

ä½¿ç”¨æ–¹æ³•ï¼š
python test_mmchange_as_tool.py [--device cuda:0]
"""

import sys
import os
import torch
import traceback

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = "/root/Remote-Sensing-ChatGPT"
sys.path.insert(0, PROJECT_ROOT)

def print_section(title):
    """æ‰“å°åˆ†éš”çº¿æ ‡é¢˜"""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)

def test_change_detection_function():
    """æµ‹è¯• ChangeDetectionFunction æ˜¯å¦å¯ä»¥å¯¼å…¥"""
    print_section("æ­¥éª¤ 1: æµ‹è¯• ChangeDetectionFunction å¯¼å…¥")
    
    try:
        from RStask import ChangeDetectionFunction
        print(f"  âœ“ ChangeDetectionFunction å¯¼å…¥æˆåŠŸ")
        return True, ChangeDetectionFunction
    except Exception as e:
        print(f"  âœ— ChangeDetectionFunction å¯¼å…¥å¤±è´¥:")
        print(f"    {e}")
        traceback.print_exc()
        return False, None

def test_change_detection_function_init(ChangeDetectionFunction, device='cuda:0'):
    """æµ‹è¯• ChangeDetectionFunction åˆå§‹åŒ–"""
    print_section(f"æ­¥éª¤ 2: æµ‹è¯• ChangeDetectionFunction åˆå§‹åŒ– (è®¾å¤‡: {device})")
    
    # å¦‚æœæ˜¯ cuda è®¾å¤‡ï¼Œæ£€æŸ¥æ˜¯å¦å¯ç”¨
    if 'cuda' in device:
        if not torch.cuda.is_available():
            print(f"  âš  CUDA ä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ° CPU")
            device = 'cpu'
        else:
            print(f"  âœ“ CUDA å¯ç”¨")
    
    try:
        func = ChangeDetectionFunction(device)
        print(f"  âœ“ ChangeDetectionFunction åˆå§‹åŒ–æˆåŠŸ")
        print(f"  âœ“ ç±»å‹: {type(func)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ inference æ–¹æ³•
        if hasattr(func, 'inference'):
            print(f"  âœ“ inference æ–¹æ³•å­˜åœ¨")
        else:
            print(f"  âœ— inference æ–¹æ³•ä¸å­˜åœ¨")
            return False, None
        
        return True, func
    except Exception as e:
        print(f"  âœ— ChangeDetectionFunction åˆå§‹åŒ–å¤±è´¥:")
        print(f"    {e}")
        traceback.print_exc()
        return False, None

def test_change_detection_tool_wrapper(device='cuda:0'):
    """æµ‹è¯• RSChatGPT ä¸­çš„ ChangeDetection å·¥å…·å°è£…"""
    print_section(f"æ­¥éª¤ 3: æµ‹è¯• ChangeDetection å·¥å…·å°è£…")
    
    try:
        # å¯¼å…¥ RSChatGPT-shell ä¸­çš„ ChangeDetection ç±»
        # ç”±äºæ–‡ä»¶ååŒ…å«è¿å­—ç¬¦ï¼Œéœ€è¦ä½¿ç”¨ importlib
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "RSChatGPT_shell", 
            "/root/Remote-Sensing-ChatGPT/RSChatGPT-shell.py"
        )
        RSChatGPT_shell = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(RSChatGPT_shell)
        ChangeDetection = RSChatGPT_shell.ChangeDetection
        print(f"  âœ“ ChangeDetection å·¥å…·ç±»å¯¼å…¥æˆåŠŸ")
        
        # åˆå§‹åŒ–å·¥å…·
        if 'cuda' in device and not torch.cuda.is_available():
            device = 'cpu'
            print(f"  âš  CUDA ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")
        
        tool = ChangeDetection(device)
        print(f"  âœ“ ChangeDetection å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
        
        # æ£€æŸ¥å·¥å…·å±æ€§
        if hasattr(tool, 'inference'):
            print(f"  âœ“ inference æ–¹æ³•å­˜åœ¨")
        else:
            print(f"  âœ— inference æ–¹æ³•ä¸å­˜åœ¨")
            return False, None
        
        # æ£€æŸ¥ prompts è£…é¥°å™¨è®¾ç½®çš„å±æ€§
        if hasattr(tool.inference, 'name'):
            print(f"  âœ“ å·¥å…·åç§°: {tool.inference.name}")
        else:
            print(f"  âš  å·¥å…·åç§°æœªè®¾ç½®")
        
        if hasattr(tool.inference, 'description'):
            print(f"  âœ“ å·¥å…·æè¿°: {tool.inference.description[:100]}...")
        else:
            print(f"  âš  å·¥å…·æè¿°æœªè®¾ç½®")
        
        return True, tool
    except Exception as e:
        print(f"  âœ— ChangeDetection å·¥å…·å°è£…æµ‹è¯•å¤±è´¥:")
        print(f"    {e}")
        traceback.print_exc()
        return False, None

def create_test_images():
    """åˆ›å»ºæµ‹è¯•å›¾åƒ"""
    from PIL import Image
    import numpy as np
    
    test_dir = "/root/Remote-Sensing-ChatGPT/test_images"
    os.makedirs(test_dir, exist_ok=True)
    
    pre_image_path = os.path.join(test_dir, "test_pre.png")
    post_image_path = os.path.join(test_dir, "test_post.png")
    
    # å¦‚æœæµ‹è¯•å›¾åƒå·²å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨
    if os.path.exists(pre_image_path) and os.path.exists(post_image_path):
        return pre_image_path, post_image_path
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    # å‰æ—¶ç›¸ï¼šç»¿è‰²èƒŒæ™¯
    pre_img = np.ones((256, 256, 3), dtype=np.uint8) * [50, 150, 50]
    np.random.seed(42)
    noise = np.random.randint(-20, 20, (256, 256, 3))
    pre_img = np.clip(pre_img + noise, 0, 255).astype(np.uint8)
    
    # åæ—¶ç›¸ï¼šæ·»åŠ å»ºç­‘ç‰©
    post_img = pre_img.copy()
    post_img[50:100, 50:150] = [150, 150, 150]
    post_img[120:200, 180:230] = [140, 140, 140]
    
    Image.fromarray(pre_img).save(pre_image_path)
    Image.fromarray(post_img).save(post_image_path)
    
    return pre_image_path, post_image_path

def test_tool_inference(tool, pre_image_path, post_image_path):
    """æµ‹è¯•å·¥å…·æ¨ç†"""
    print_section("æ­¥éª¤ 4: æµ‹è¯•å·¥å…·æ¨ç†åŠŸèƒ½")
    
    # æµ‹è¯•åœºæ™¯
    test_cases = [
        {
            'name': 'åœºæ™¯ 1: åŸºæœ¬å˜åŒ–æ£€æµ‹ï¼ˆä¸¤ä¸ªå›¾åƒï¼‰',
            'inputs': f'{pre_image_path},{post_image_path}',
        },
        {
            'name': 'åœºæ™¯ 2: å¸¦å˜åŒ–æè¿°çš„æ£€æµ‹',
            'inputs': f'{pre_image_path},{post_image_path},buildings have been constructed',
        },
    ]
    
    results = {}
    
    for test_case in test_cases:
        print(f"\n  {test_case['name']}")
        print(f"  è¾“å…¥: {test_case['inputs']}")
        print()
        
        try:
            result = tool.inference(test_case['inputs'])
            print(f"  âœ“ è°ƒç”¨æˆåŠŸ")
            print(f"  è¾“å‡º: {result}")
            
            # æ£€æŸ¥è¾“å‡ºæ ¼å¼
            if 'Output:' in result and '.png' in result:
                print(f"  âœ“ è¾“å‡ºæ ¼å¼æ­£ç¡®ï¼ˆåŒ…å«è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼‰")
                results[test_case['name']] = True
            else:
                print(f"  âš  è¾“å‡ºæ ¼å¼å¯èƒ½ä¸å®Œæ•´")
                results[test_case['name']] = True
                
        except Exception as e:
            print(f"  âœ— è°ƒç”¨å¤±è´¥:")
            print(f"    {e}")
            traceback.print_exc()
            results[test_case['name']] = False
    
    return results

def test_tool_error_handling(tool):
    """æµ‹è¯•å·¥å…·é”™è¯¯å¤„ç†"""
    print_section("æ­¥éª¤ 5: æµ‹è¯•å·¥å…·é”™è¯¯å¤„ç†")
    
    error_cases = [
        {
            'name': 'é”™è¯¯è¾“å…¥ 1: åªæä¾›ä¸€ä¸ªå›¾åƒ',
            'inputs': 'single_image.png',
            'should_fail': True
        },
        {
            'name': 'é”™è¯¯è¾“å…¥ 2: ç©ºå­—ç¬¦ä¸²',
            'inputs': '',
            'should_fail': True
        },
        {
            'name': 'é”™è¯¯è¾“å…¥ 3: ä¸å­˜åœ¨çš„æ–‡ä»¶',
            'inputs': 'nonexistent1.png,nonexistent2.png',
            'should_fail': True
        },
    ]
    
    results = {}
    
    for error_case in error_cases:
        print(f"\n  {error_case['name']}")
        print(f"  è¾“å…¥: '{error_case['inputs']}'")
        
        try:
            result = tool.inference(error_case['inputs'])
            
            if error_case['should_fail']:
                # æœŸæœ›å¤±è´¥ä½†æˆåŠŸäº†
                if 'Error' in result or 'error' in result.lower():
                    print(f"  âœ“ æ­£ç¡®å¤„ç†é”™è¯¯ï¼ˆè¿”å›é”™è¯¯ä¿¡æ¯ï¼‰")
                    print(f"  é”™è¯¯ä¿¡æ¯: {result}")
                    results[error_case['name']] = True
                else:
                    print(f"  âš  æœªæ­£ç¡®å¤„ç†é”™è¯¯ï¼ˆåº”è¯¥è¿”å›é”™è¯¯ä¿¡æ¯ï¼‰")
                    print(f"  è¿”å›: {result}")
                    results[error_case['name']] = False
            else:
                print(f"  âœ“ è°ƒç”¨æˆåŠŸ")
                results[error_case['name']] = True
                
        except Exception as e:
            if error_case['should_fail']:
                print(f"  âœ“ æ­£ç¡®æŠ›å‡ºå¼‚å¸¸")
                print(f"  å¼‚å¸¸: {type(e).__name__}: {e}")
                results[error_case['name']] = True
            else:
                print(f"  âœ— æ„å¤–å¼‚å¸¸:")
                print(f"    {e}")
                results[error_case['name']] = False
    
    return results

def test_langchain_tool_integration(device='cuda:0'):
    """æµ‹è¯•ä¸ LangChain Tool çš„é›†æˆ"""
    print_section("æ­¥éª¤ 6: æµ‹è¯• LangChain Tool é›†æˆ")
    
    try:
        from langchain.agents.tools import Tool
        
        # å¯¼å…¥ ChangeDetectionï¼ˆä½¿ç”¨ importlib å¤„ç†è¿å­—ç¬¦æ–‡ä»¶åï¼‰
        import importlib.util
        spec = importlib.util.spec_from_file_location(
            "RSChatGPT_shell", 
            "/root/Remote-Sensing-ChatGPT/RSChatGPT-shell.py"
        )
        RSChatGPT_shell = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(RSChatGPT_shell)
        ChangeDetection = RSChatGPT_shell.ChangeDetection
        
        # åˆ›å»º ChangeDetection å®ä¾‹
        if 'cuda' in device and not torch.cuda.is_available():
            device = 'cpu'
        
        change_detection = ChangeDetection(device)
        
        # åˆ›å»º LangChain Tool
        tool = Tool(
            name=change_detection.inference.name if hasattr(change_detection.inference, 'name') else "Change Detection",
            func=change_detection.inference,
            description=change_detection.inference.description if hasattr(change_detection.inference, 'description') else "Change detection tool"
        )
        
        print(f"  âœ“ LangChain Tool åˆ›å»ºæˆåŠŸ")
        print(f"  å·¥å…·åç§°: {tool.name}")
        print(f"  å·¥å…·æè¿°: {tool.description[:100]}...")
        
        # æµ‹è¯• tool è°ƒç”¨
        pre_img, post_img = create_test_images()
        test_input = f"{pre_img},{post_img}"
        
        print(f"\n  æµ‹è¯• Tool è°ƒç”¨...")
        print(f"  è¾“å…¥: {test_input}")
        
        result = tool.run(test_input)
        print(f"  âœ“ Tool è°ƒç”¨æˆåŠŸ")
        print(f"  ç»“æœ: {result[:200]}...")
        
        return True
        
    except Exception as e:
        print(f"  âœ— LangChain Tool é›†æˆæµ‹è¯•å¤±è´¥:")
        print(f"    {e}")
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='MMchange.py ä½œä¸º Tool è°ƒç”¨éªŒè¯')
    parser.add_argument('--device', type=str, default='cuda:0',
                       choices=['cuda:0', 'cuda:1', 'cpu'],
                       help='è®¾å¤‡ç±»å‹')
    parser.add_argument('--skip_langchain', action='store_true',
                       help='è·³è¿‡ LangChain é›†æˆæµ‹è¯•')
    
    args = parser.parse_args()
    
    print("\n")
    print("â•”" + "â•" * 68 + "â•—")
    print("â•‘" + " " * 13 + "MMchange.py ä½œä¸º Tool è°ƒç”¨éªŒè¯" + " " * 24 + "â•‘")
    print("â•š" + "â•" * 68 + "â•")
    
    # è®°å½•æµ‹è¯•ç»“æœ
    test_results = {}
    
    # 1. æµ‹è¯• ChangeDetectionFunction å¯¼å…¥
    success, ChangeDetectionFunction = test_change_detection_function()
    test_results['ChangeDetectionFunction å¯¼å…¥'] = success
    if not success:
        print("\nâŒ ChangeDetectionFunction å¯¼å…¥å¤±è´¥")
        return False
    
    # 2. æµ‹è¯• ChangeDetectionFunction åˆå§‹åŒ–
    success, func = test_change_detection_function_init(ChangeDetectionFunction, args.device)
    test_results['ChangeDetectionFunction åˆå§‹åŒ–'] = success
    if not success:
        print("\nâŒ ChangeDetectionFunction åˆå§‹åŒ–å¤±è´¥")
        return False
    
    # 3. æµ‹è¯• ChangeDetection å·¥å…·å°è£…
    success, tool = test_change_detection_tool_wrapper(args.device)
    test_results['ChangeDetection å·¥å…·å°è£…'] = success
    if not success:
        print("\nâŒ ChangeDetection å·¥å…·å°è£…å¤±è´¥")
        return False
    
    # 4. å‡†å¤‡æµ‹è¯•å›¾åƒ
    print_section("å‡†å¤‡æµ‹è¯•å›¾åƒ")
    pre_image_path, post_image_path = create_test_images()
    print(f"  âœ“ æµ‹è¯•å›¾åƒå‡†å¤‡å®Œæˆ")
    print(f"    å‰æ—¶ç›¸: {pre_image_path}")
    print(f"    åæ—¶ç›¸: {post_image_path}")
    
    # 5. æµ‹è¯•å·¥å…·æ¨ç†
    inference_results = test_tool_inference(tool, pre_image_path, post_image_path)
    test_results.update(inference_results)
    
    # 6. æµ‹è¯•é”™è¯¯å¤„ç†
    error_results = test_tool_error_handling(tool)
    test_results.update(error_results)
    
    # 7. æµ‹è¯• LangChain Tool é›†æˆï¼ˆå¯é€‰ï¼‰
    if not args.skip_langchain:
        langchain_success = test_langchain_tool_integration(args.device)
        test_results['LangChain Tool é›†æˆ'] = langchain_success
    
    # æ€»ç»“
    print_section("éªŒè¯ç»“æœæ€»ç»“")
    
    all_passed = True
    for test_name, result in test_results.items():
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"  {test_name:40s}: {status}")
        if not result:
            all_passed = False
    
    print("\n" + "=" * 70)
    if all_passed:
        print("  ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼MMchange.py å¯ä»¥ä½œä¸º Tool è°ƒç”¨")
    else:
        print("  âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    print("=" * 70 + "\n")
    
    return all_passed

if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)

